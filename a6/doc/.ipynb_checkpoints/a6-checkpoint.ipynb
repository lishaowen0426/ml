{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 340 Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as ling\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.sparse import csr_matrix as sparse_matrix\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={mechanics:5}\n",
    "\n",
    "\n",
    "The above points are allocated for following the [homework submission instructions](https://github.ugrad.cs.ubc.ca/CPSC340-2017W-T2/home/blob/master/homework_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Finding similar items\n",
    "\n",
    "For this question we'll be using the [Amazon product data set](http://jmcauley.ucsd.edu/data/amazon/). The author of the data set has asked for the following citations:\n",
    "\n",
    "> Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering.\n",
    "> R. He, J. McAuley.\n",
    "> WWW, 2016.\n",
    "> \n",
    "> Image-based recommendations on styles and substitutes.\n",
    "> J. McAuley, C. Targett, J. Shi, A. van den Hengel.\n",
    "> SIGIR, 2015.\n",
    "\n",
    "We will focus on the \"Patio, Lawn, and Garden\" section. Download the [ratings](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Patio_Lawn_and_Garden.csv) and place the file in the `data` directory with the original filename. Once you do that, the code below should load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2VNYWOPJ13AFP</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1259798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A20DWVV8HML3AW</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1371081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3RVP3YBYYOPRH</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1257984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A28XY55TP3Q90O</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1314144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3VZW1BGUQO0V3</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1308268800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0  A2VNYWOPJ13AFP  0981850006     5.0  1259798400\n",
       "1  A20DWVV8HML3AW  0981850006     5.0  1371081600\n",
       "2  A3RVP3YBYYOPRH  0981850006     5.0  1257984000\n",
       "3  A28XY55TP3Q90O  0981850006     5.0  1314144000\n",
       "4  A3VZW1BGUQO0V3  0981850006     5.0  1308268800"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"ratings_Patio_Lawn_and_Garden.csv\"\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", filename), \"rb\") as f:\n",
    "    ratings = pd.read_csv(f,names=(\"user\",\"item\",\"rating\",\"timestamp\"))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd also like to construct the user-product matrix `X`. Let's see how big it would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 993490\n",
      "The average rating: 4.006400668350965\n",
      "Number of users: 714791\n",
      "Number of items: 105984\n",
      "Fraction nonzero: 1.3114269915944552e-05\n",
      "Size of full X matrix: 606.05 GB\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ratings, item_key=\"item\", user_key=\"user\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"The average rating:\", np.mean(ratings[\"rating\"]))\n",
    "\n",
    "    d = len(set(ratings[item_key]))\n",
    "    n = len(set(ratings[user_key]))\n",
    "    print(\"Number of users:\", n)\n",
    "    print(\"Number of items:\", d)\n",
    "    print(\"Fraction nonzero:\", len(ratings)/(n*d))\n",
    "    print(\"Size of full X matrix: %.2f GB\" % ((n*d)*8/1e9))\n",
    "\n",
    "    return n,d\n",
    "\n",
    "n,d = get_stats(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "600 GB! That is way too big. We don't want to create that matrix. On the other hand, we see that we only have about 1 million ratings, which would be around 8 MB ($10^6$ numbers $\\times$ at 8 bytes per double precision floating point number). Much more manageable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_X(ratings,n,d,user_key=\"user\",item_key=\"item\"):\n",
    "    user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(n))))\n",
    "    item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(d))))\n",
    "\n",
    "    user_inverse_mapper = dict(zip(list(range(n)), np.unique(ratings[user_key])))\n",
    "    item_inverse_mapper = dict(zip(list(range(d)), np.unique(ratings[item_key])))\n",
    "\n",
    "    user_ind = [user_mapper[i] for i in ratings[user_key]]\n",
    "    item_ind = [item_mapper[i] for i in ratings[item_key]]\n",
    "\n",
    "    X = sparse_matrix((ratings[\"rating\"], (user_ind, item_ind)), shape=(n,d))\n",
    "    \n",
    "    return X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind\n",
    "\n",
    "X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind = create_X(ratings, n, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "#X.toarray()[user_mapper['A2VNYWOPJ13AFP']][item_mapper['0981850006']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check\n",
    "print(X.shape) # should be number of users by number of items\n",
    "print(X.nnz)   # number of nonzero elements -- should equal number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947920"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Above: verifying our estimate of 8 MB to store sparse `X`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Find the following items:\n",
    "\n",
    "1. the item with the most reviews\n",
    "2. the item with the most total stars\n",
    "3. the item with the highest average stars\n",
    "\n",
    "Then, find the names of these items by looking them up with the url https://www.amazon.com/dp/ITEM_ID, where `ITEM_ID` is the id of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/dp/B00CFM0P7Y\n"
     ]
    }
   ],
   "source": [
    "url_amazon = \"https://www.amazon.com/dp/%s\"\n",
    "# example:\n",
    "print(url_amazon % 'B00CFM0P7Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item with the most reviews is https://www.amazon.com/dp/B000HCLLMM\n",
      "item with the most stars is https://www.amazon.com/dp/B000HCLLMM\n",
      "item with the highest avg is https://www.amazon.com/dp/0981850006\n"
     ]
    }
   ],
   "source": [
    "num_reviews = np.sum(X!=0,axis = 0)\n",
    "total_stars = np.sum(X,axis =0)\n",
    "\n",
    "#most reviews\n",
    "ind = np.argmax(num_reviews)\n",
    "most_reviews = item_inverse_mapper[ind]\n",
    "print('item with the most reviews is ' + url_amazon%most_reviews)\n",
    "# most stars\n",
    "ind = np.argmax(total_stars)\n",
    "most_stars = item_inverse_mapper[ind]\n",
    "print('item with the most stars is ' + url_amazon%most_stars)\n",
    "\n",
    "num = np.sum(X!=0, axis = 0, dtype = float)\n",
    "num [num==0] = float('inf')\n",
    "avg = total_stars / num_reviews\n",
    "ind = np.argmax(avg)\n",
    "highest_avg = item_inverse_mapper[ind]\n",
    "print('item with the highest avg is ' + url_amazon%highest_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "rubric={reasoning:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the following histograms \n",
    "\n",
    "1. The number of ratings per user\n",
    "2. The number of ratings per item\n",
    "3. The ratings themselves\n",
    "\n",
    "For the first two, use\n",
    "```\n",
    "plt.yscale('log', nonposy='clip')\n",
    "``` \n",
    "to put the histograms on a log-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'number of users')"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJLG+v8rzBwg4/r+8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e9ef0f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "num_ratings = np.sum (X!=0, axis = 1)\n",
    "\n",
    "#unique, counts = np.unique(num_ratings, return_counts=True)\n",
    "plt.hist(num_ratings)\n",
    "plt.yscale('log',nonposy = 'clip')\n",
    "plt.xlabel('number of ratings')\n",
    "plt.ylabel('number of users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-488-2440c100495c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#number of ratings per item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_ratings_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ratings_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnonposy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'clip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of ratings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3002\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3004\u001b[0;31m                       stacked=stacked, normed=normed, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3005\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   6284\u001b[0m                 patch = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[1;32m   6285\u001b[0m                                  \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6286\u001b[0;31m                                  color=c, **{bottom_kwarg: bottom})\n\u001b[0m\u001b[1;32m   6287\u001b[0m                 \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6288\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[0mymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintervaly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0mbar_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBarContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mautoscale_view\u001b[0;34m(self, tight, scalex, scaley)\u001b[0m\n\u001b[1;32m   2240\u001b[0m             \u001b[0mstickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m             \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m             \u001b[0my_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m                 \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_stickies\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npCYMviQ18f+GmWq6NWLIwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e9f081be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#number of ratings per item\n",
    "num_ratings_item = np.sum (X!=0, axis = 0)\n",
    "plt.hist(num_ratings_item)\n",
    "plt.yscale('log',nonposy = 'clip')\n",
    "plt.xlabel('number of ratings')\n",
    "plt.ylabel('number of items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#rating itself\n",
    "plt.hist(ratings['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Use scikit-learn's [NearestNeighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html) object (which uses Euclidean distance by default) to find the 5 items most similar to [Brass Grill Brush 18 Inch Heavy Duty and Extra Strong, Solid Oak Handle](https://www.amazon.com/dp/B00CFM0P7Y). \n",
    "\n",
    "The code block below grabs the row of `X` associated with the grill brush. The mappers take care of going back and forther between the IDs (like `B00CFM0P7Y`) and the indices of the sparse array (0,1,2,...).\n",
    "\n",
    "Note: keep in mind that `NearestNeighbors` is for taking neighbors across rows, but here we're working across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/dp/B00CFM0P7Y\n"
     ]
    }
   ],
   "source": [
    "grill_brush = \"B00CFM0P7Y\"\n",
    "grill_brush_ind = item_mapper[grill_brush]\n",
    "grill_brush_vec = X[:,grill_brush_ind]\n",
    "\n",
    "print(url_amazon % grill_brush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar items(Euclidean distance) are: \n",
      "['B00CFM0P7Y', 'B00IJB5MCS', 'B00IJB4MLA', 'B00EXE4O42', 'B00743MZCM']\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "Xhat = np.transpose(X)\n",
    "g = np.transpose(grill_brush_vec)\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(Xhat) \n",
    "neighbors = neigh.kneighbors(g)\n",
    "euc_neigh = [item_inverse_mapper[i] for i in neighbors[1].flatten()]\n",
    "print('The 5 most similar items(Euclidean distance) are: ')\n",
    "print(euc_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Using cosine similarity instead of Euclidean distance in `NearestNeighbors`, find the 5 products most similar to `B00CFM0P7Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "def cos_similarity (x,y):\n",
    "    return np.dot(x,y) / (ling.norm(X) * ling.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar items(cosine similarity) are: \n",
      "['B00CFM0P7Y', 'B00IJB5MCS', 'B00IJB8F3G', 'B00IJB4MLA', 'B00EF45AHU']\n"
     ]
    }
   ],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=5 , metric = 'cosine')\n",
    "neigh.fit(Xhat) \n",
    "neighbors = neigh.kneighbors(g)\n",
    "cos_neigh = [item_inverse_mapper[i] for i in neighbors[1].flatten()]\n",
    "print('The 5 most similar items(cosine similarity) are: ')\n",
    "print(cos_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5\n",
    "rubric={reasoning:2}\n",
    "\n",
    "For each of the two metrics, compute the compute the total popularity (total stars) of each of the 5 items and report it. Do the results make sense given what we discussed in class about Euclidean distance vs. cosine similarity? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euc total stars is \n",
      "[[ 1244.   266.   205.     5.     5.]]\n",
      "Cos total stars is \n",
      "[[ 1244.   266.   438.   205.   311.]]\n",
      "Grill brush total stars is \n",
      "1244.0\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "euc_ind = [item_mapper[i] for i in euc_neigh]\n",
    "cos_ind = [item_mapper[i] for i in cos_neigh]\n",
    "\n",
    "sum_stars = np.sum(X, axis = 0)\n",
    "euc_sum = sum_stars[0,euc_ind]\n",
    "cos_sum = sum_stars[0,cos_ind]\n",
    "grill_sum = sum_stars[0,grill_brush_ind]\n",
    "print('Euc total stars is ')\n",
    "print(euc_sum)\n",
    "\n",
    "print('Cos total stars is ')\n",
    "print(cos_sum)\n",
    "\n",
    "print('Grill brush total stars is ')\n",
    "print(grill_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can easily seen that the cosine similarity is able to find items that are more similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6\n",
    "rubric={reasoning:3}\n",
    "\n",
    "PCA gives us an approximation $X \\approx ZW$ where the rows of $Z$ contain a length-$k$ latent feature vectors for each user and the columns of $W$ contain a length-$k$ latent feature vectors for each item.\n",
    "\n",
    "Another strategy for finding similar items is to run PCA and then search for nearest neighbours with Euclidean distance in the latent feature space, which is hopefully more meaningful than the original \"user rating space\". In other words, we run nearest neighbors on the columns of $W$. Using $k=10$ and scikit-learn's [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) to perform the dimensionality reduction, find the 5 nearest neighbours to the grill brush using this method. You can access $W$ via the `components_` field of the `TruncatedSVD` object, after you fit it to the data. \n",
    "\n",
    "Briefly comment on your results.\n",
    "\n",
    "Implementation note: when you call on `NearestNeighbors.kneighbors`, it expects the input to be a 2D array. There's some weirdness here because `X` is a scipy sparse matrix but your `W` will be a dense matrix, and they behave differently in subtle ways. If you get an error like \"Expected 2D array, got 1D array instead\" then this is your problem: a column of `W` is technically a 1D array but a column of `X` has dimension $1\\times n$, which is technically a 2D array. You can take a 1D numpy array and add an extra first dimension to it with `array[None]`.\n",
    "\n",
    "Conceptual note 1: We are using the \"truncated\" rather than full SVD since a full SVD would involve dense $d\\times d$ matrices, which we've already established are too big to deal with. And then we'd only use the first $k$ rows of it anyway. So a full SVD would be both impossible and pointless.\n",
    "\n",
    "Conceptual note 2: as discussed in class, there is a problem here, which is that we're not ignoring the missing entries. You could get around this by optimizing the PCA objective with gradient descent, say using `findMin` from previous assignments. But we're just going to ignore that for now, as the assignment seems long enough as it is (or at least it's hard for me to judge how long it will take because it's new)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "svd.fit(X)\n",
    "W = svd. components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar items(pca) are: \n",
      "['B00CFM0P7Y', 'B000W46XSM', 'B000H1SJ8C', 'B000X9BNG8', 'B000HCR8C4']\n",
      "pca total stars is \n",
      "[[ 1244.   399.   432.   232.   453.]]\n"
     ]
    }
   ],
   "source": [
    "g = np.transpose(W[:,grill_brush_ind])\n",
    "What = np.transpose(W)\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(What) \n",
    "g= g[None,:]\n",
    "neighbors = neigh.kneighbors(g)\n",
    "\n",
    "pca_neigh = [item_inverse_mapper[i] for i in neighbors[1].flatten()]\n",
    "print('The 5 most similar items(pca) are: ')\n",
    "print(pca_neigh)\n",
    "\n",
    "pca_ind = [item_mapper[i] for i in pca_neigh]\n",
    "sum_stars = np.sum(X, axis = 0)\n",
    "pca_sum = sum_stars[0,pca_ind]\n",
    "\n",
    "print('pca total stars is ')\n",
    "print(pca_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is closer than the one using cosine similarity, I think this is mainly because when the number of dimensions is reduced, it becomes much clearer what does the \"distance\" mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: putting it all together in a CPSC 340 \"mini-project\"\n",
    "rubric={reasoning:25}\n",
    "\n",
    "In this open-ended mini-project, you'll explore the [UCI default of credit card clients data set](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients). There are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default payment next month\" in the data. The rest of the columns can be used as features. \n",
    "\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Download the data set and load it in. Since the data comes as an MS Excel file, I suggest using [`pandas.read_excel`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html) to read it in. See [Lecture 2](https://github.ugrad.cs.ubc.ca/CPSC340-2017W-T2/home/blob/master/lectures/L2.ipynb) for an example of using pandas.\n",
    "2. Perform exploratory data analysis on the data set. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Randomly split the data into train, validation, test sets. The validation set will be used for your experiments. The test set should be saved until the end, to make sure you didn't overfit on the validation set. You are welcome to use scikit-learn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), which takes care of both shuffling and splitting. \n",
    "4. Try scikit-learn's [DummyClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) as a baseline model.\n",
    "5. Try logistic regression as a first real attempt. Make a plot of train/validation error vs. regularization strength. What’s the lowest validation error you can get?\n",
    "6. Explore the features, which are described on the UCI site. Explore preprocessing the features, in terms of transforming non-numerical variables, feature scaling, change of basis, etc. Did this improve your results?\n",
    "7. Try 3 other models aside from logistic regression, at least one of which is a neural network. Can you beat logistic regression? (For the neural net(s), the simplest choice would probably be to use scikit-learn's [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), but you are welcome to use any software you wish. )\n",
    "8. Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. I won't make it a strict requirement, but I recommend checking out one of the following (the first two are simple scikit-learn tools, the latter two are much more sophisticated algorithms and require installing new packages): \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)\n",
    "9. Explore feature selection for this problem. What are some particularly relevant and irrelevant features? Can you improve on your original logistic regression model if you first remove some irrelevant features?\n",
    "10. Take your best model overall. Train it on the combined train/validation set and run it on the test set once. Does the test error agree fairly well with the validation error from before? Do you think you’ve had issues with optimization bias? Report your final test error directly in your README.md file as well as in your report.\n",
    "\n",
    "**Submission format:**\n",
    "Your submission should take the form of a \"report\" that includes both code and an explanation of what you've done. You don't have to include everything you ever tried - it's fine just to have your final code - but it should be reproducible. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code.\n",
    "\n",
    "**Assessment:**\n",
    "We plan to grade and fairly leniently. We don't have some secret target accuracy that you need to achieve to get a good grade. You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results. For example, if you write something like, \"And then I noticed the model was overfitting, so I decided to stop using regularization\" - then, well, that's not good. If you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "**And...**\n",
    "This style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-6 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, don't do it out of perfectionism... do it because you're learning and enjoying it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
      "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
      "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
      "       'default payment next month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE AND REPORT HERE, IN A SENSIBLE FORMAT\n",
    "\n",
    "#read data\n",
    "xls_path = os.getcwd()+'/default of credit card clients.xls'\n",
    "df = pd.read_excel(xls_path,skiprows=[0])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average age for default payment is 35.725738\n",
      "The average education for default payment is 1.894665\n"
     ]
    }
   ],
   "source": [
    "#summary statistics\n",
    "ages =np.array( df['AGE'] )\n",
    "educations = np.array(df['EDUCATION'])\n",
    "default_payment = np.array(df['default payment next month'])\n",
    "sex = np.array(df['SEX'])\n",
    "\n",
    "default_avg_age = np.mean(ages[default_payment == 1])\n",
    "default_avg_edu = np.mean(educations[default_payment == 1])\n",
    "\n",
    "print('The average age for default payment is {:f}'.format(default_avg_age))\n",
    "print('The average education for default payment is {:f}'.format(default_avg_edu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD7CAYAAABdXO4CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24ec6dfd8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_sex = sex[default_payment == 1]\n",
    "unique, counts = np.unique(default_sex, return_counts=True)\n",
    "labels = ['male', 'female']\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(counts,labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Sex ratio of people fail to pay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAcSMzMrxYHEzMxK+f8A8BplsfwNYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24ecb0127b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = df[['AGE','default payment next month']]\n",
    "a = a.sort_values('AGE')\n",
    "ages = a['AGE']\n",
    "payment = a['default payment next month']\n",
    "c = ages[payment == 1]\n",
    "plt.hist(c,normed = 1)\n",
    "plt.title('Ratio of different ages for people fail to pay')\n",
    "plt.xlabel('ages')\n",
    "plt.ylabel('ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I discard the ID column since it have no influence to the data\n",
    "total = df.values\n",
    "X = total[:,1:-1]\n",
    "y = total[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle = True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier: \n",
      "Training error: 0.339740\n",
      "Validation error: 0.342500\n",
      "Test error: 0.342667\n"
     ]
    }
   ],
   "source": [
    "#Dummy classifier\n",
    "dummy_model = DummyClassifier()\n",
    "dummy_model.fit(X_train,y_train)\n",
    "training_error = np.mean(dummy_model.predict(X_train)!=y_train)\n",
    "validation_error = np.mean(dummy_model.predict(X_valid)!=y_valid)\n",
    "test_error = np.mean(dummy_model.predict(X_test)!=y_test)\n",
    "\n",
    "print('Dummy classifier: ')\n",
    "print('Training error: %f'%training_error)\n",
    "print('Validation error: %f'%validation_error)\n",
    "print('Test error: %f'%test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22135417  0.22135417  0.22135417  0.22135417  0.22130208  0.22135417\n",
      "  0.22135417  0.22135417  0.22135417  0.22135417  0.22135417  0.22135417]\n",
      "[ 0.22395833  0.22395833  0.22395833  0.22395833  0.22395833  0.22395833\n",
      "  0.22395833  0.22395833  0.22395833  0.22395833  0.22395833  0.22395833]\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "\n",
    "a = np.linspace(-3,8,num=12)\n",
    "b = np.ones(12)*10\n",
    "C = np.power(b,a)\n",
    "\n",
    "training_errors = np.zeros(12)\n",
    "validation_errors = np.zeros(12)\n",
    "\n",
    "i=0\n",
    "for c in C:\n",
    "    log_model = LogisticRegression(C = c)\n",
    "    log_model.fit(X_train,y_train)\n",
    "    training_errors[i] = np.mean(log_model.predict(X_train)!=y_train)\n",
    "    validation_errors[i] = np.mean(log_model.predict(X_valid)!=y_valid)\n",
    "    i += 1\n",
    "\n",
    "print(training_errors)\n",
    "print(validation_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'training error/validation error vs regularization strength')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QBjZmaFcIAxM7NCOMCYmVkh/j9Xs8H7AIPG2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24eb97cff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(C,training_errors,label='training error')\n",
    "plt.plot(C,validation_errors,label = 'validation error')\n",
    "plt.legend(['training error','validation error'])\n",
    "plt.xlabel('regularization strength')\n",
    "plt.ylabel('error')\n",
    "plt.title('training error/validation error vs regularization strength')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice the error is almost the same, I think this is because we only have 24 features and a huge number of exmples, it is hard to overfit too much, thus the regularization strength makes little difference here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lishaowen/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Explore the features\n",
    "X_train_stand = scale(X_train)\n",
    "#y_train_stand = scale(y_train)\n",
    "X_valid_stand = scale(X_valid)\n",
    "#y_valid_stand = scale(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error with X standardized:0.189271 \n",
      "Validation error with X standardized: 0.189167\n",
      "Trainning error without X standardized:0.221354 \n",
      "Validation error without X standardized: 0.223958\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_stand,y_train)\n",
    "stand_training_error= np.mean(model.predict(X_train_stand)!=y_train)\n",
    "stand_validation_error = np.mean(model.predict(X_valid_stand)!=y_valid)\n",
    "print('Trainning error with X standardized:%f '% stand_training_error)\n",
    "print('Validation error with X standardized: %f'% stand_validation_error)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "training_error= np.mean(model.predict(X_train)!=y_train)\n",
    "validation_error = np.mean(model.predict(X_valid)!=y_valid)\n",
    "print('Trainning error without X standardized:%f '% training_error)\n",
    "print('Validation error without X standardized: %f'% validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is some improvement here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error for neural network:0.451354 \n",
      "Validation error for neural network: 0.435000\n"
     ]
    }
   ],
   "source": [
    "#neural_network\n",
    "\n",
    "neu_model = MLPClassifier()\n",
    "neu_model.fit(X_train,y_train)\n",
    "training_error= np.mean(neu_model.predict(X_train)!=y_train)\n",
    "validation_error = np.mean(neu_model.predict(X_valid)!=y_valid)\n",
    "print('Trainning error for neural network:%f '% training_error)\n",
    "print('Validation error for neural network: %f'% validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error for knn:0.183542 \n",
      "Validation error for knn: 0.246458\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_error= np.mean(knn.predict(X_train)!=y_train)\n",
    "validation_error = np.mean(knn.predict(X_valid)!=y_valid)\n",
    "print('Trainning error for knn:%f '% training_error)\n",
    "print('Validation error for knn: %f'% validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error for Decision Tree:0.148177 \n",
      "Validation error for Decision Tree: 0.194583\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tree = DecisionTreeClassifier( max_depth = 10)\n",
    "tree.fit(X_train, y_train)\n",
    "training_error= np.mean(tree.predict(X_train)!=y_train)\n",
    "validation_error = np.mean(tree.predict(X_valid)!=y_valid)\n",
    "print('Trainning error for Decision Tree:%f '% training_error)\n",
    "print('Validation error for Decision Tree: %f'% validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these three models perform better than logistic regression, decision tree is the closet one\n",
    "but I am a little bit surprised that neural network performs such badly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error for decitsion tree with hyperparameter \"max_depth\" optimized:0.175417 \n",
      "Validation error for decision tree with hyperparameter \"max_depth\" optimized: 0.185833\n",
      "The best max_depth is 3\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization\n",
    "param_dist = {\"max_depth\": np.linspace(1,10,10)}\n",
    "\n",
    "t = DecisionTreeClassifier( )\n",
    "grid = GridSearchCV( t, param_grid=param_dist,return_train_score=False)\n",
    "grid.fit(X_train, y_train)\n",
    "training_error= np.mean(grid.predict(X_train)!=y_train)\n",
    "validation_error = np.mean(grid.predict(X_valid)!=y_valid)\n",
    "print('Trainning error for decitsion tree with hyperparameter \"max_depth\" optimized:%f '% training_error)\n",
    "print('Validation error for decision tree with hyperparameter \"max_depth\" optimized: %f'% validation_error)\n",
    "print('The best max_depth is %d'%grid.best_params_ ['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs a little bit better but not that much and the max depth is suprisingly only 3. I suppose this is because the dataset has several features that are very representative and have a strong relationship with the label, thus with themselves, it is already enough to predict the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error for random forest with hyperparameter  optimized:0.166979 \n",
      "Validation error for random forest with hyperparameter  optimized: 0.184792\n",
      "The best parameters are: \n",
      "{'bootstrap': True, 'max_depth': 9.0, 'max_features': 5, 'min_samples_split': 90}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\"max_depth\": np.linspace(1,10,10),\n",
    "              \"max_features\": np.linspace(1,5,5,dtype = int),\n",
    "              \"min_samples_split\": np.linspace(10,100,10,dtype= int),\n",
    "              \"bootstrap\": [True, False]}\n",
    "\n",
    "rt = RandomForestClassifier(max_features=None)\n",
    "grid = GridSearchCV( rt, param_grid=param_dist,return_train_score=False)\n",
    "grid.fit(X_train, y_train)\n",
    "training_error= np.mean(grid.predict(X_train)!=y_train)\n",
    "validation_error = np.mean(grid.predict(X_valid)!=y_valid)\n",
    "print('Trainning error for random forest with hyperparameter  optimized:%f '% training_error)\n",
    "print('Validation error for random forest with hyperparameter  optimized: %f'% validation_error)\n",
    "print('The best parameters are: ')\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I can change the number of max_features here, but it will become super slow, so I just limit it\n",
    " to 5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error for feature selection:0.187135 \n",
      "Validation error for feature selection: 0.198958\n",
      "Index of features selected: \n",
      "[1 2 3 5]\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "model = LogisticRegression(penalty = 'l1', C = 0.1)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "selected = np.absolute(model.coef_)>=0.1\n",
    "selected = np.where(selected==True)[1]\n",
    "X_train_selected = X_train[:,selected]\n",
    "X_valid_selected = X_valid[:,selected]\n",
    "X_test_selected = X_test[:,selected]\n",
    "model = LogisticRegression(penalty = 'l2', C = 1)\n",
    "model.fit(X_train_selected,y_train)\n",
    "training_error= np.mean(model.predict(X_train_selected)!=y_train)\n",
    "validation_error = np.mean(model.predict(X_valid_selected)!=y_valid)\n",
    "print('Trainning error for feature selection:%f '% training_error)\n",
    "print('Validation error for feature selection: %f'% validation_error)\n",
    "print('Index of features selected: ')\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost the same after feature selection....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning error for feature selection and standarization:0.187083 \n",
      "Validation error for feature selection and standarization: 0.194167\n",
      "Test error for feature selection and standarization: 0.187667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lishaowen/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#For final model: I use standardization and feature selection for logistic regression\n",
    "X_train_selected_stand = scale(X_train_selected)\n",
    "X_valid_selected_stand = scale(X_valid_selected)\n",
    "X_test_selected_stand = scale(X_test_selected)\n",
    "model = LogisticRegression(penalty = 'l2', C = 1)\n",
    "model.fit(X_train_selected_stand,y_train)\n",
    "training_error= np.mean(model.predict(X_train_selected_stand)!=y_train)\n",
    "validation_error = np.mean(model.predict(X_valid_selected_stand)!=y_valid)\n",
    "test_error = np.mean(model.predict(X_test_selected_stand)!=y_test)\n",
    "print('Trainning error for feature selection and standarization:%f '% training_error)\n",
    "print('Validation error for feature selection and standarization: %f'% validation_error)\n",
    "print('Test error for feature selection and standarization: %f'% test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Very short answer questions\n",
    "rubric={reasoning:7}\n",
    "\n",
    "1. Why is it difficult for a standard collaborative filtering model to make good predictions for new items?\n",
    "2. Consider a fully connected neural network with layer sizes (10,20,20,5); that is, the input dimensionality is 10, there are two hidden layers each of size 20, and the output dimensionality is 5. How many parameters does the network have, including biases?\n",
    "3. Why do we need nonlinear activation functions in neural networks?\n",
    "4. Assuming we could globally minimize the neural network objectve, how does the depth of a neural network affect the fundamental trade-off?\n",
    "5. List 3 forms of regularization we use to prevent overfitting in neural networks.\n",
    "6. Assuming we could globally minimize the neural network objectve, how would the size of the filters in a convolutational neural network affect the fundamental trade-off?\n",
    "7. Why do people say convolutional neural networks just a special case of a fully-connected (regular) neural networks? What does this imply about the number of learned parameters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "It uses latent_factor approach, so it can only learn about existing items\n",
    "\n",
    "\n",
    "2.\n",
    "\n",
    "Layer 1:\n",
    "The input dimensionality is 10 and the layer size is 20, so W has size 20*10 = 200. Then we have 20 bias as well, so the first layer has 220 parameters\n",
    "\n",
    "Layer 2:\n",
    "The input dimensionality is 20 and the layer size is 20, so W has size 20*20 = 400. Then we have 20 bias as well, so the second layer has 420 parameters\n",
    "\n",
    "Output:\n",
    "The input dimensionality is 20 and the final output dimensionality is 5, so W is 20*5 = 100 plus 5 bias, so it is 105\n",
    "\n",
    "Sum up all it is 220+420+105 = 745\n",
    "\n",
    "\n",
    "3.\n",
    "\n",
    "If it is linear, then w1*w2*w3*.... is just another w which would be same as other linear model\n",
    "\n",
    "\n",
    "4.\n",
    "\n",
    "As it gets deeper, we have more parameters and the model becomes more complex, so the overfitting becomes more serious. We will have higher error for the estimation of test error\n",
    "\n",
    "\n",
    "\n",
    "5.\n",
    "\n",
    "(a) Typical L2 regularization for v, W1,W2,W3...\n",
    "(b) Early stopping by monitoring the validation error as we run\n",
    "(c) Dropout by randomly setting xi and zi to 0\n",
    "\n",
    "6.\n",
    "\n",
    "As the size becomes larger, we have more parameters and the model becoms more complex which leads to more overfitting\n",
    "\n",
    "\n",
    "7.\n",
    "\n",
    "It is just a fully connected neural network with sparse W. Since we can set many parameters to zeros, this leads to less parameters and less overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
